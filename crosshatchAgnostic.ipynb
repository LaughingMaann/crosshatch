{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2410c7d6ac37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os, sys, glob, scipy, argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy import fftpack, fft\n",
    "from scipy.fftpack import fftshift, irfft, rfft \n",
    "from scipy.signal import blackman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "count = 1\n",
    "#pathTest = '/Users/estepark/Documents/week1_thurs/GRR_Sample/Vermouth_EVT/20181126/Images/Reg/White/*.Png'\n",
    "pathTest = '/Users/estepark/Documents/week1_thurs/GRR_Sample/Vermouth_EVT/20181126/Images/Reg/White'\n",
    "isdir = os.path.isdir(pathTest) \n",
    "\"\"\"\n",
    "class CrossHatch(object):\n",
    "    \"\"\"\n",
    "    FUNCTION: \n",
    "    ** generate plots and pass/fail outputs based on frequency vs. distance \n",
    "    INPUTS: \n",
    "    ** path: the path that contains all the images\n",
    "    ** rows: the number of rows to iterate thru\n",
    "    ** col: the number of columns to iterate thru\n",
    "    ?* filterType: crossHatch, faintLine, edgeGlow, luminanceHotspot, colorHotspot\n",
    "    OUTPUTS:\n",
    "    ** dict key: what # the image is in the dir\n",
    "    ** dict values:  \n",
    "    \"\"\"\n",
    "    def __init__(self, path , rows, col):\n",
    "        assert os.path.isdir(pathTest), \"hey\"\n",
    "        self.path = path\n",
    "        self.rows = rows\n",
    "        self.col = col\n",
    "    def createDict(self):\n",
    "        # define scharr kernal to convolve along diagonals\n",
    "        kern = [[0, 1,  0], [1, 0, -1],[ 0, -1 ,0]]\n",
    "        # define counter to number how many images in the dir\n",
    "        count = 1\n",
    "        white = {}\n",
    "        img = [] # 1st value in dictionary\n",
    "        imgScharr = [] # 2nd value in dictionary\n",
    "        score = [] # will be used as numerical value > 0 that quantifies how many cols are crosshatched\n",
    "        print(\"Image directory: \" + str(self.path))\n",
    "        print(\"Number of rows: \" + str(self.rows))\n",
    "        print(\"Number of col: \" + str(self.col))\n",
    "        for fname in glob.glob(self.path+'/*.Png'):\n",
    "            #print(fname)\n",
    "            img.append(cv.imread(fname)) #first value pair\n",
    "            plt.figure()\n",
    "            plt.title('White Image ' + str(count) + \": flipped from RGB --> BGR\")\n",
    "            plt.imshow(img[-1])\n",
    "            #==============================================================\n",
    "            # 1st VALUE, original pixel BGR mat \n",
    "            #==============================================================\n",
    "            im = img.copy()\n",
    "            imgray = cv.cvtColor(im[-1], cv.COLOR_BGR2GRAY)\n",
    "            #print(imgray)\n",
    "            \n",
    "            #==============================================================\n",
    "            # 2nd VALUE, Scharr pixel mat\n",
    "            #==============================================================\n",
    "            imgray = cv.bilateralFilter(imgray, 15, 75, 75)\n",
    "            ret, thresh = cv.threshold(imgray, 10, 255, cv.THRESH_BINARY)\n",
    "            contours, hierarchy = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "            im_with_contours = cv.drawContours(im[-1], contours, -1, (0,255,0), 6)\n",
    "            diag_img = signal.convolve2d(imgray, np.array(kern), boundary='symm', mode='same')\n",
    "            imgScharr.append(diag_img) #2nd value pair\n",
    "            plt.figure()\n",
    "            plt.title('White Image ' + str(count) + \": Scharr operator + Low pass filter\")\n",
    "            #plt.imshow(diag_img+101, cmap=\"gray\")\n",
    "            plt.imshow(diag_img , cmap=\"gray\")\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            #================================================================\n",
    "            # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html\n",
    "            # https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.html\n",
    "            # ^sobelx vs. sobely, we see that sobely will perform better \n",
    "            # https://docs.opencv.org/trunk/da/d22/tutorial_py_canny.html\n",
    "            # https://stackoverflow.com/questions/54950777/opencv-drawing-contours-with-various-methods-on-a-poor-image\n",
    "            #================================================================\n",
    "            plt.figure()\n",
    "            diag_cpy = (((diag_img.copy()+2))/4*255).astype(np.uint8) #bc min=-2 and max=+2\n",
    "\n",
    "\n",
    "            print('max = {}, min = {}'.format(np.max(diag_cpy), np.min(diag_cpy)))\n",
    "            print(' diag shape = ',diag_cpy.shape)\n",
    "            edged = cv.Canny(diag_cpy, 160, 230)\n",
    "            plt.figure()\n",
    "            plt.imshow(edged, cmap=\"gray\")\n",
    "            plt.show()\n",
    "            \n",
    "            sobelx = cv.Sobel(diag_cpy,cv.CV_64F,1,0,ksize=5)  \n",
    "            sobely = cv.Sobel(diag_cpy,cv.CV_64F,0,1,ksize=5)\n",
    "            print('sobel max = {}, min = {}'.format(np.max(sobely), np.min(sobely)))\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(sobelx)\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "            plt.imshow(sobely)\n",
    "            plt.show()\n",
    "            cnts,_ = cv.findContours(edged.copy()[:,:50], cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "            print('contours shape {}'.format(np.array(cnts).shape))\n",
    "            backtorgb = cv.cvtColor(diag_cpy,cv.COLOR_GRAY2RGB)\n",
    "            cv.drawContours(backtorgb, cnts, -1, (0, 255, 0), 2)\n",
    "            \n",
    "            plt.imshow(backtorgb)\n",
    "            plt.title('Edged Contours, Scharr -> canny')\n",
    "            plt.show()\n",
    "        \n",
    "            \n",
    "            #====================================================================================================\n",
    "            # 3rd VALUE, 4 subplots: 1st) spatial domain BGR, 2) plot np.fft.fft, 3) stem fftpack.fftfreq\n",
    "            #====================================================================================================\n",
    "            samplingFreq = 100\n",
    "            samplingInterval = 1 / samplingFreq\n",
    "            beginTime = 0\n",
    "            endTime = self.col\n",
    "            teim = np.arange(beginTime,endTime, 1)\n",
    "            countPeaks = [] # max valu = 646, counts how many stem peaks there are per column\n",
    "            \n",
    "            for i in range(self.col):\n",
    "                #figure , axis = plt.subplots(3,1)\n",
    "                freqRowSamps = np.linspace(0,self.rows-1, self.rows)\n",
    "                # the issue is x-axis png ranges from 481, y-axis ranges 646, but these values change slightly based on image\n",
    "                amplitude = imgray[:,i] # ampltiude == # of rows\n",
    "                \n",
    "                \n",
    "                #print(\"--------------------------------------------------------\")\n",
    "                #plt.subplots_adjust ( hspace = 3)\n",
    "                #time domain representation for CrossHatch periodic signal\n",
    "                #axis[0].set_title('White Image #%s' % (count) +', Col #%s' % (i) + \" Spatial Intensity vs. Pixel distance\" )\n",
    "                #axis[0].set_xlabel('Pixel Distance along y-axis ')\n",
    "                #axis[0].set_ylabel('Pixel intensity')\n",
    "                #axis[0].plot(amplitude)\n",
    "                \n",
    "                \"\"\"\n",
    "                # https://pythontic.com/visualization/signals/fouriertransform_fft\n",
    "                plt.subplots_adjust ( hspace = 3)\n",
    "                # frequency domain representation\n",
    "                fourierTransf = np.fft.fft(amplitude)/ len(amplitude) # normalize amplitude\n",
    "                fourierTransf = fourierTransf[range(int(len(amplitude)/2))] #exclude sampling freq??\n",
    "                tpCount = len(amplitude)\n",
    "                val = np.arange(int(tpCount/2))\n",
    "                timePer = tpCount/samplingFreq\n",
    "                freq = val/timePer \n",
    "                axis[1].set_title('White Image # %s' % (count) +', Col # %s' % (i) + \" FFT Intensity vs. Pixel distance fft.fft plot \" )\n",
    "                axis[1].set_xlabel('Frequency along y-axis pixel locations')\n",
    "                axis[1].set_ylabel('Amplitude')\n",
    "                axis[1].plot(freq, abs(fourierTransf))\n",
    "                # https://docs.scipy.org/doc/scipy-0.14.0/reference/tutorial/fftpack.html\n",
    "                # Windowing the signal with a dedicated window function helps mitigate spectral leakage.\n",
    "                # a Blackman window from scipy.signal and shows the effect of windowing\n",
    "                # try irfft, rfft, fftshift?\n",
    "                plt.subplots_adjust ( hspace = 3)\n",
    "                yf = fft(amplitude)\n",
    "                w = blackman(self.rows)\n",
    "                ywf = irfft(w*yf)\n",
    "                axis[3].set_title('White Image # %s' % (count) +', Col # %s' % (i) + \" FFT Intensity vs. Pixel distance fft.fft semilogy\" )\n",
    "                axis[3].set_xlabel('Frequency along y-axis pixel locations')\n",
    "                axis[3].set_ylabel('Amplitude')\n",
    "                #axis[3].set_xlim(-samplingFreq / 2, samplingFreq / 2)\n",
    "                #axis[3].set_ylim(-2, 100000)\n",
    "                axis[3].semilogy(frequen, np.abs(ywf))\n",
    "                print(\"--------------------------------------------------------\")\n",
    "                \"\"\"\n",
    "                \n",
    "                # https://www.oreilly.com/library/view/elegant-scipy/9781491922927/ch04.html\n",
    "                #plt.subplots_adjust ( hspace = 3)\n",
    "                X = fftpack.fft(amplitude)\n",
    "                amplitude1 = fftpack.fftfreq(len(amplitude))*samplingFreq\n",
    "                #axis[1].set_title('Image #%s' % (count) +', Col #%s' % (i) + \" FFT Intensity vs. Pixel distance (fftpack.fftfreq) stem \" )\n",
    "                #axis[1].set_xlabel('Frequency along y-axis pixel locations')\n",
    "                #axis[1].set_ylabel('Amplitude')\n",
    "                #axis[1].set_xlim(-5, samplingFreq / 1.2)\n",
    "                #axis[1].set_ylim(-2, 600)\n",
    "                #print(max(np.abs(X))) \n",
    "                #axis[1].stem(freqRowSamps, np.abs(X), use_line_collection = True) \n",
    "                \n",
    "                #plt.subplots_adjust ( hspace = 3)     \n",
    "                # https://pythonawesome.com/overview-of-the-peaks-dectection-algorithms-available-in-python/\n",
    "                #freqPeaks = scipy.signal.find_peaks( np.abs(X) , height=[200, 1000000] )\n",
    "                freqPeaks = scipy.signal.find_peaks( np.abs(X) , height=[200, 5000] )\n",
    "                indexPeaks = freqPeaks[0]\n",
    "                heightPeaks = np.array(list(freqPeaks[1].values()) , dtype = object)\n",
    "                heightPeaks = heightPeaks[0]\n",
    "                #print('height peaks: ' + str(heightPeaks))\n",
    "                #print('index peaks: ' + str(indexPeaks))\n",
    "                #axis[2].set_title('Image #%s' % (count) +', Col #%s' % (i) + \" Peaks\")\n",
    "                #axis[2].set_ylabel('Amplitude')\n",
    "                #axis[2].set_xlabel('Frequency along y-axis pixel locations')\n",
    "                #axis[2].set_xlim(-5, samplingFreq / 1.2)\n",
    "                #axis[2].set_ylim(-2, 600)\n",
    "                if heightPeaks.size > 0:\n",
    "                    #axis[2].stem(indexPeaks,heightPeaks, use_line_collection=True)\n",
    "                    countPeaks.append(len(heightPeaks))\n",
    "                else:\n",
    "                    countPeaks.append(0)\n",
    "            \n",
    "            print('length crosshatch is ' + str(len(countPeaks)))\n",
    "            isCrossHatch = sum(countPeaks)\n",
    "            score.append(isCrossHatch)\n",
    "            plt.figure()\n",
    "            plt.plot(countPeaks,'bo')\n",
    "            plt.title(\"Number of peaks in FFT spectrum vs. Column location\")\n",
    "            plt.xlabel(\"Column #\")\n",
    "            plt.ylabel(\"Number of peaks\")\n",
    "            plt.show()\n",
    "            \n",
    "            print( \" img[count-1]\" , img[count-1])\n",
    "            print(\"imgScharr[count-1],\" ,imgScharr[count-1])\n",
    "            print(\"score[count-1])\" ,score)\n",
    "            print(\"score[count-1])\" ,score[count-1])\n",
    "            white.update( { 'white %s' % (count): (img[count-1]  , imgScharr[count-1], score[count-1])  } )\n",
    "\n",
    "            count = count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTest = '/Users/estepark/Documents/week1_thurs/GRR_Sample/Vermouth_EVT/20181126/Images/Reg/White'\n",
    "isdir = os.path.isdir(pathTest) \n",
    "\n",
    "stuff = CrossHatch(path = pathTest, rows=  646, col= 480)\n",
    "stuff.createDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img)\n",
    "count = 1\n",
    "\"\"\"\n",
    "objective: \n",
    "1) iterate through every 600 columns, find greatest variation in peaks\n",
    "\n",
    "2) rank the greatest peak variations\n",
    "\"\"\"\n",
    "White = {}\n",
    "for i in range(10):\n",
    "    #print(count)\n",
    "    White.update( { 'white %s' % (count): (img[i]  , imgScharr[i]) } )\n",
    "    count = count +1 \n",
    "    #print(White)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "amplitude1 = [100,5,150,3,200,1,150,9,100] \n",
    "time = [1,2,3,4,5,6,7,8,9]\n",
    "plt.plot(time,amplitude1)\n",
    "a=scipy.signal.find_peaks(amplitude1,height=[125,175 ]  )\n",
    "print(\"index is \" + str(a[0]))\n",
    "print(a[1].keys())\n",
    "heights = np.array(list(a[1].values() ), dtype = float)\n",
    "#heights = heights[0]\n",
    "print(\"heights is \" +str(heights))\n",
    "print(len( heights  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels =  '/Users/estepark/Documents/week9_tues/label'\n",
    "annotations = '/Users/estepark/Documents/week11_mon/Vermouth_HVT/2018-09-10 D HVT HG8A/20180910/Data/HiResMesh/label'\n",
    "originals = '/Users/estepark/Documents/week11_mon/Vermouth_HVT/2018-09-10 D HVT HG8A/20180910/Data/HiResMesh/results'\n",
    "\n",
    "for fname in glob.glob(annotations+'/*.png'):\n",
    "    serNum = fname.split('/')[-1][:-4] \n",
    "    \n",
    "    annotation  = cv.imread(fname) # green line annotated label\n",
    "    annotation_full = np.copy(annotation)\n",
    "    annotation_binary = np.zeros(annotation.shape[:2])\n",
    "    \n",
    "    for i in range(annotation.shape[0]): \n",
    "        for j in range(annotation.shape[1])[::-1]:\n",
    "            if annotation[i][j][0] == annotation[i][j][1] == annotation[i][j][2]:\n",
    "                continue\n",
    "            else:\n",
    "                annotation_full[i][0:j][:] = annotation_full[i][j][:]\n",
    "                annotation_binary[i][0:j] = 1\n",
    "                break\n",
    "    \n",
    "    original = cv.imread(originals+'/{}.png'.format(serNum), cv.IMREAD_GRAYSCALE) # original label without annotation\n",
    "    imgFilt = cv.bilateralFilter(original, 15, 75, 75)\n",
    "    diag_img = signal.convolve2d(imgFilt, np.array(kern), boundary='symm', mode='same') # scharr filter \n",
    "    scharr = (((diag_img+2))/4*255).astype(np.uint8) #normalize after scharr, bc min=-2 and max=+2\n",
    "    original = (original-np.min(original))/(np.max(original) - np.min(original)) # normalize label [0,1]\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(serNum+' label line')\n",
    "    plt.imshow(annotation)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(serNum+' label full')\n",
    "    plt.imshow(annotation_full)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(serNum+' label binary')\n",
    "    plt.imshow(annotation_binary, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(serNum+' label original')\n",
    "    plt.imshow(original, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(serNum+' scharr')\n",
    "    plt.imshow(scharr, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(serNum+' un scharr')\n",
    "    plt.imshow(diag_img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
