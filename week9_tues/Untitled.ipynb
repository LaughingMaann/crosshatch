{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3,4,5,6]\n",
    "for i in range(0,len(a),2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long crosshatch plots SUBPLOTS FOR FINDING THE THRESHOLD\n",
    "\n",
    "\n",
    "path= '/Users/estepark/Documents/week6_fri/Data/'\n",
    "# row 500, 1275, 1350\n",
    "def subPlotPlotLong(path, plotRows=[]):\n",
    "    pixelIntensities = []\n",
    "    fftAmps = []\n",
    "    fnames = []\n",
    "    count = []\n",
    "    for fname in (glob.glob(path+'/*.csv')) :\n",
    "        Lv_csv = pd.read_csv(fname, skiprows=[0], header=None)\n",
    "        for i in range(0,1500):\n",
    "            # find element's index corresponding to u'\n",
    "            if ( Lv_csv[0][i] ==\"u'\" ): \n",
    "                # save all Lv matrix values until u' index\n",
    "                Lvindex = int(np.where(Lv_csv == Lv_csv[0][i])[0] ) \n",
    "                break     # as soon as matched index valid, exit & search no further\n",
    "        # concatenated Lv matrix that excludes u' and v' matrix in csv file\n",
    "        Lv = np.array(Lv_csv[0: Lvindex], dtype=\"float32\" ) \n",
    "        \"\"\"\n",
    "        INPUT == Short cross hatches\n",
    "        FN == Short cross hatch search\n",
    "        OUTPUT == ALL THE SUBPLOTS AND SHIET\n",
    "        \"\"\"\n",
    "        # split the name of the csv as plt title\n",
    "        spltName = fname.split('/')[-1][:-4] \n",
    "        fnames.append(spltName)\n",
    "        plt.figure()\n",
    "        imgLv = np.array(Lv, dtype = \"uint8\") #cv2 for 8u and 32f images in function 'bilateralFilter'\n",
    "        imgLvcopy = imgLv.copy()\n",
    "        #cv.imread(Lv.x1)\n",
    "        plt.title(\"Lv from csv file converted to image \\n {}\".format(spltName))\n",
    "        plt.imshow(np.array(Lv), cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "        # provide Scharr kernel\n",
    "        kern = [[0, 1,  0], [1, 0, -1],[ 0, -1 ,0]]\n",
    "        imgrayLv = cv.bilateralFilter(imgLv, 20, 75, 75)\n",
    "        diag_imgLv= signal.convolve2d(imgrayLv, np.array(kern) , boundary ='symm', mode='same')\n",
    "        plt.figure()\n",
    "        plt.imshow(diag_imgLv, cmap = \"gray\")\n",
    "        plt.title(\"Scharr + LPF \\n {}\".format(spltName))\n",
    "        plt.show()\n",
    "\n",
    "        # scale back to [0,255], becuase convolve2d changes ranges [-2,+2]\n",
    "        diag_cpy = (((diag_imgLv.copy()+2))/4*255).astype(np.uint8) #bc min=-2 and max=+2\n",
    "        #print('max = {}, min = {}'.format(np.max(diag_cpy), np.min(diag_cpy)))  #confirm min/max\n",
    "        #print(' diag shape = ',diag_cpy.shape) \n",
    "        edged = cv.Canny(diag_cpy, 160, 230)\n",
    "\n",
    "        #sobelx = cv.Sobel(diag_cpy,cv.CV_64F,0,1,ksize=5)\n",
    "        #plt.figure()\n",
    "        #plt.imshow(diag_cpy)\n",
    "        #plt.title('diag_cpy scaled to 0,255')\n",
    "        #plt.show()\n",
    "        #==================================================\n",
    "        # perform short crosshatch # FFT scores vs. # row slice, around row #1200 should see period \n",
    "        #==================================================\n",
    "        samplingFreq = 100\n",
    "        samplingInterval = 1 / samplingFreq\n",
    "        beginTime = 0\n",
    "        print(imgLv.shape)\n",
    "        \"\"\"\n",
    "        numRows == len of col is a 1360(height)x1020(width), then 1360==len of col == #of rows\n",
    "        \"\"\"\n",
    "        numRows = imgLv.shape[0] \n",
    "        numCols = imgLv.shape[1]\n",
    "        # for loop for short crosshatch is endTime = numCol\n",
    "        #freqRowSamps = np.linspace(0, numCols, numCols) # for short crosshatch\n",
    "        freqRowSamps = np.linspace(0, numRows, numRows) # for short crosshatch\n",
    "        endTime = numRows\n",
    "        teim = np.arange(beginTime,endTime, 1)\n",
    "        countPeaks = [] \n",
    "        score = []\n",
    "        print(\"numrows: {}\" .format(imgLv.shape[0]))\n",
    "        print(\"numCols: {}\" .format(imgLv.shape[1]))\n",
    "\n",
    "        filePixelIntensities = []\n",
    "        fileFftAmps = []\n",
    "        for i in range(numCols):\n",
    "        #for i in plotRows: \n",
    "            # for every i'th row, slice all columns [i,:]: => and append into amplitude \n",
    "            #amplitude = imgrayLv[i,:] # ampltiude == # of cols, for short crosshatch\n",
    "            amplitude = imgrayLv[:,i] # ampltiude == # of cols, for short crosshatch\n",
    "            filePixelIntensities.append(amplitude)\n",
    "            #================================================================================\n",
    "            #time domain representation for CrossHatch periodic signal\n",
    "            #================================================================================\n",
    "            #plt.figure()\n",
    "            #plt.title('Row #%s' % (i) + \" Spatial Intensity vs. Pixel distance \\n{}\".format(spltName) )\n",
    "            #plt.xlabel('Pixel Distance along x-axis ')\n",
    "            #plt.ylabel('Pixel intensity of Lv mat [Nits]')\n",
    "            #plt.plot(amplitude)\n",
    "\n",
    "            #=================================================================================\n",
    "            #frequency domain of short CrossHatch\n",
    "            # ---->https://www.oreilly.com/library/view/elegant-scipy/9781491922927/ch04.html\n",
    "            #=================================================================================\n",
    "            #plt.figure()\n",
    "            X = fftpack.fft(amplitude)\n",
    "            fileFftAmps.append(np.abs(X))\n",
    "            amplitude1 = fftpack.fftfreq(len(amplitude))*samplingFreq\n",
    "        \n",
    "            #plt.title('Row #%s' % (i) + \" Abs FFT Magnitude vs. Frequency \\n{}\".format(spltName) )\n",
    "            #plt.xlabel('Frequency along x-axis [cycles/image]')\n",
    "            #plt.ylabel('Abs amplitude FFT')\n",
    "            #plt.xlim(-1, samplingFreq / 2)\n",
    "            #plt.ylim(-1, 4000)\n",
    "            #plt.stem(freqRowSamps, np.abs(X), use_line_collection = True) \n",
    "\n",
    "            #=================================================================================\n",
    "            #count number of peaks that surpass that threshold, dont xlim ylim\n",
    "            #plt.subplots_adjust ( hspace = 3)     \n",
    "            # https://pythonawesome.com/overview-of-the-peaks-dectection-algorithms-available-in-python/\n",
    "            #=================================================================================\n",
    "            freqPeaks = scipy.signal.find_peaks( np.abs(X) , distance=1, width=0, height=[250, 3000] )\n",
    "            \n",
    "            indexPeaks = freqPeaks[0]\n",
    "            heightPeaks = freqPeaks[1]['peak_heights']\n",
    "           \n",
    "\n",
    "            if heightPeaks.size > 0:\n",
    "                #plt.stem(indexPeaks,heightPeaks, use_line_collection=True)\n",
    "                countPeaks.append(heightPeaks)\n",
    "                #plt.show()\n",
    "            else:\n",
    "                countPeaks.append([0])\n",
    "\n",
    "        countPeaks = np.array(countPeaks) \n",
    "        isCrossHatch = np.hstack(countPeaks) #flattend last of countPeaks\n",
    "        \n",
    "        score = sum(isCrossHatch)\n",
    "        print(\"score is {}\".format(score))\n",
    "        sumCols = [np.sum(cp) for cp in countPeaks]\n",
    "        count.append(sumCols)\n",
    "\n",
    "\n",
    "    plt.plot(count[0],'b-')\n",
    "    plt.plot(count[1],'r-')\n",
    "    plt.plot(count[2],'g-')\n",
    "    plt.xlabel('pixel location along short x-axis')\n",
    "    plt.ylabel('Sum of FFT magnitude')\n",
    "    plt.title('sum of FFT mag vs. pixel location x-axis \\n{}'.format(spltName))\n",
    "    plt.legend((line1, line2, line3), 'a','b','c',loc=\"upper right\")\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "        # perform long crosshatch\n",
    "        pixelIntensities.append(np.array(filePixelIntensities))\n",
    "        fftAmps.append(np.array(fileFftAmps))\n",
    "    \n",
    "    #pixelIntensities = np.array(pixelIntensities)\n",
    "    #fftAmps = np.array(fftAmps)\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(len(plotRows), 2,figsize=(20,25))\n",
    "    for j, row in enumerate(plotRows): \n",
    "        for k in range(len(fnames)): \n",
    "            ax[j, 0].plot(pixelIntensities[k][j], label='{}'.format(fnames[k])) \n",
    "            ax[j, 1].stem(fftAmps[k][j], label='{}'.format(fnames[k]), use_line_collection=True, markerfmt='C{}o'.format(k),linefmt='C{}-'.format(k))\n",
    "        ax[j,0].set_title('Row #{}'.format(row) + \" Spatial Intensity vs. Pixel distance \", fontsize=20 )\n",
    "        ax[j,0].set_xlabel('Pixel Distance along x-axis ' , fontsize=18)\n",
    "        ax[j,0].set_ylabel('Pixel intensity of Lv mat [Nits]',fontsize=18)\n",
    "\n",
    "        ax[j,0].legend()\n",
    "        \n",
    "        ax[j,1].set_title('Row #{}'.format(row) + \" Abs FFT Magnitude vs. Frequency \", fontsize=20)\n",
    "        ax[j,1].set_xlabel('Frequency along x-axis [cycles/image]',fontsize=18)\n",
    "        ax[j,1].set_ylabel('Abs amplitude FFT',fontsize=18)\n",
    "        ax[j,1].set_xlim(-1, samplingFreq / 2)\n",
    "        ax[j,1].set_ylim(-1, 2000)\n",
    "\n",
    "        ax[j,1].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "path= '/Users/estepark/Documents/week6_fri/Data/'\n",
    "# row 500, 1275, 1350\n",
    "subPlotPlotLong(path, plotRows=[0, 100, 700])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "a= [1,10,3,100]\n",
    "a=np.array(a)\n",
    "c =map(lambda x: 10*math.log10(x) , a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<map object at 0x7f83f506f650>]\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 10.        ,  4.77121255, 20.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*np.log10(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7f83f507ea90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 10.0, 4.771212547196624, 20.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
